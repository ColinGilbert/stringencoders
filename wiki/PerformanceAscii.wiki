#summary Performance for ascii encoders
#labels Featured

=== Sequential Ctypes toupper ===
A simple example is doing upper casing an ascii string.  A standard implementation might look like

{{{
void toupper_copy1(char* dest, const char* str, int len)
{
    int i;
    for (i = 0; i < len; ++i) {
        // toupper is defined in <ctype.h>                                                                                              
        *dest++ = toupper(str[i]);
    }
    *dest = 0;
}
}}}

The problem here is some clibs have crap versions of `toupper`.  They have to look up the 'C Locale' and use a complicated table and bit shifts.  A better version might be


=== Sequential Direct Computation ===

{{{
void toupper_copy2(char* dest, const char* str, int len)
{
    int i;
    unsigned char c;
    for (i = 0; i < len; ++i) {
        c = str[i];
        *dest++ = (c >= 'a' && c <= 'z') ? c : (c -32);
    }
    *dest = 0;
}
}}}

One some platforms, this simple version is quite a bit faster already. 


=== Sequential Table Lookup ===

The problem here is that for each byte we have to do two comparisons and maybe a subtraction.  This can all be precomputed.

{{{
static char toupper_map = {0x00, 0x01, ... 'A' .. 'Z' ... 'A', .. 'Z'... 0xFF};

void toupper_copy3(char* dest, const char* str, int len)
{
    int i;
    for (i = 0; i < len; ++i) {
        *dest++ = toupper_map[(unsigned char)(str[i])];
    }
    *dest = 0;
}
}}}

This may or may not be faster still depending on your compiler or CPU.  


=== Parallel Table Lookup ===
However modern CPUs can have multiple registers and can either do multiple things at once or pipeline multiple request.  For instance

{{{
void toupper_copy4(char* dest, const char* str, int len)
    const int leftover = len % 4;
    const int imax = len - leftover;
    const uint8_t* s = (const uint8_t*) str;
    for (i = 0; i != imax ; i+=4) {
        /*                                                                                                                              
          it's important to make these variables                                                                                        
          it helps the optimizer to figure out what to do                                                                               
        */
        c1 = s[i], c2=s[i+1], c3=s[i+2], c4=s[i+3];
        dest[0] = gsToUpperMap[c1];
        dest[1] = gsToUpperMap[c2];
        dest[2] = gsToUpperMap[c3];
        dest[3] = gsToUpperMap[c4];
        dest += 4;
    }
    switch (leftover) {
    case 3: *dest++ = gsToUpperMap[s[i++]];
    case 2: *dest++ = gsToUpperMap[s[i++]];
    case 1: *dest++ = gsToUpperMap[s[i]];
    case 0: *dest = '\0';
    }
}
}}}

This does things in chunks of 4.  On AMD processors this is twice as fast, on Intel, _nine_ times faster, and on my old Powerbook G4, _44 times faster_.  For details see PerformanceAscii.



== Performance Numbers ==

AMD / Linux / gLibc

{{{
$ date
Mon Jun  4 21:04:58 UTC 2007
$ ./speedtest_ascii
type    clib    direct  map     para    hsieh1  hsieh2  Final   improvement
toupper 590000  590000  580000  260000  190000  190000  230000  2.6x
}}}

Intel Core Duo / Mac OS X

{{{
$ date
Mon Jun  4 17:03:56 EDT 2007
$ ./speedtest_ascii
type    clib    direct  map     para    hsieh1  hsieh2  Final   improvement
toupper 467     81      85      66      33      32      33      14.2x
}}}

G4

Something is very wrong with the optimizer/compiler/os if we can get a 62.5x performance improvement.

{{{
$ date
Tue Jun  5 00:05:26 EDT 2007
$ ./speedtest_ascii
type    clib    direct  map     para    hsieh1  hsieh2  Final   improvement
toupper 3249    136     110     71      40      48      52      62.5x
}}}